[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, my name is Mfundo Monchwe and I’m a data scientist, reseacher, and freelancer. I have a passion for using data to solve complex problems and help orgnanizations make data-driven decision."
  },
  {
    "objectID": "about.html#introduction",
    "href": "about.html#introduction",
    "title": "About",
    "section": "",
    "text": "Hi, my name is Mfundo Monchwe and I’m a data scientist, reseacher, and freelancer. I have a passion for using data to solve complex problems and help orgnanizations make data-driven decision."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nI have a Bachelor’s degreee and Honors degree in Data Sciences from Sol Plaatje University. I have a background in Statistics, Mathematics, and Machine Learning."
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "About",
    "section": "Work Experience",
    "text": "Work Experience\nI have worked as a Tutor for Big Data Fundamentals and Introduction to Python programming in the year 2021. This is where I taught contents such as Data wrangling, visualization, how to deal with big data, and how to use Python to solve problems."
  },
  {
    "objectID": "about.html#skills",
    "href": "about.html#skills",
    "title": "About",
    "section": "Skills",
    "text": "Skills\nI possess the following skills:\n\nPython\nR\nSQL\nMachine Learning\nData Visualization\nData Wrangling\nData Analysis\nData Cleaning\nData Mining\nData Engineering\nData Science\nStatistics\nMathematics\nResearch\nProblem Solving\nCritical Thinking\nCommunication\nTeamwork\nLeadership\nTime Management\nProject Management\nMicrosoft Office\nGoogle Suite\nLinux\nGit\nGitHub\nBayesian Methods\nRegression Analysis\nDjango"
  },
  {
    "objectID": "about.html#contact-me",
    "href": "about.html#contact-me",
    "title": "About",
    "section": "Contact Me",
    "text": "Contact Me\nIf you would like to get in touch with me, feel free to send me an email at my email-address or connect with me on LinkedIn.I look forward to hearing from you."
  },
  {
    "objectID": "Achievements.html",
    "href": "Achievements.html",
    "title": "Achievements",
    "section": "",
    "text": "1st prize on the mining digital problem at the 2022 University of Witwatersrand Hackathon\nPublished article 1 on Hackathon victory: Web link\nPublished article 2 on hackathon victory: Web link"
  },
  {
    "objectID": "Achievements.html#hackathon",
    "href": "Achievements.html#hackathon",
    "title": "Achievements",
    "section": "",
    "text": "1st prize on the mining digital problem at the 2022 University of Witwatersrand Hackathon\nPublished article 1 on Hackathon victory: Web link\nPublished article 2 on hackathon victory: Web link"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Portfolio",
    "section": "",
    "text": "Data Scientist | Researcher | Freelancer\n\n\nLinkedIn Github Resume Email"
  },
  {
    "objectID": "papers.html",
    "href": "papers.html",
    "title": "Papers",
    "section": "",
    "text": "Data security is a critical aspect of online transactions. It involves ensuring data confidentiality, data integrity, and data authenticity. While much has been done to improve data confidentiality, algorithms to address data integrity and data authenticity are rare. The RSA digital signature scheme is often used to address these issues, but it can be difficult to understand for non-experts. In this study, we showcase the implementation of a white-box RSA digital signature scheme, which is an algorithm used to ensure data confidentiality, integrity, and authenticity after online transactions. We build the proposed implementation based on the understanding that the RSA digital signature scheme is an asymmetric model that uses two keys. One key is used to sign data, and the other key is used to verify the signature. We evaluate the effectiveness of the white-box RSA digital signature scheme using a quantitative research approach, where we assess the execution time and signature verification accuracy for different values of p, q, and data lengths. We observe a tradeoff between security and execution time, and we recommend using large values of p and q for better data security.\n\n\nReference: Colin Chibaya, Mfundo Monchwe, Taryn Nicole Michael, Eli Bila Nimy. Showcasing White-Box Implementation of the RSA Digital Signature Scheme, American Journal of Computer Science and Technology. Volume 5, Issue 4, December 2022, pp. 198-203."
  },
  {
    "objectID": "papers.html#showcasing-white-box-implementation-of-the-rsa-digital-signature-scheme",
    "href": "papers.html#showcasing-white-box-implementation-of-the-rsa-digital-signature-scheme",
    "title": "Papers",
    "section": "",
    "text": "Data security is a critical aspect of online transactions. It involves ensuring data confidentiality, data integrity, and data authenticity. While much has been done to improve data confidentiality, algorithms to address data integrity and data authenticity are rare. The RSA digital signature scheme is often used to address these issues, but it can be difficult to understand for non-experts. In this study, we showcase the implementation of a white-box RSA digital signature scheme, which is an algorithm used to ensure data confidentiality, integrity, and authenticity after online transactions. We build the proposed implementation based on the understanding that the RSA digital signature scheme is an asymmetric model that uses two keys. One key is used to sign data, and the other key is used to verify the signature. We evaluate the effectiveness of the white-box RSA digital signature scheme using a quantitative research approach, where we assess the execution time and signature verification accuracy for different values of p, q, and data lengths. We observe a tradeoff between security and execution time, and we recommend using large values of p and q for better data security.\n\n\nReference: Colin Chibaya, Mfundo Monchwe, Taryn Nicole Michael, Eli Bila Nimy. Showcasing White-Box Implementation of the RSA Digital Signature Scheme, American Journal of Computer Science and Technology. Volume 5, Issue 4, December 2022, pp. 198-203."
  },
  {
    "objectID": "papers.html#bayesian-convolutional-neural-networks-for-coronavirus-lung-image-classification-with-uncertainty-estimation",
    "href": "papers.html#bayesian-convolutional-neural-networks-for-coronavirus-lung-image-classification-with-uncertainty-estimation",
    "title": "Papers",
    "section": "Bayesian Convolutional Neural Networks for Coronavirus Lung Image Classification with Uncertainty Estimation",
    "text": "Bayesian Convolutional Neural Networks for Coronavirus Lung Image Classification with Uncertainty Estimation\n\n\nPrevious attempts to identify or predict coronavirus using lung imaging data have not incorporated a way to quantify the uncertainty in their predictions. Additionally, these models need more certainty quantification to raise questions about their reliability. In this chapter, we address these issues by modeling a coronavirus classification model that utilizes a Bayesian convolutional neural networks (BCNNs) approach. This probabilistic machine learning approach allows for the estimation of uncertainty, providing insight into the reliability of coronavirus image classification. We test the accuracy of the model using a comprehensive radiographical lung image dataset, revealing its capability to deliver significant uncertainty information. Furthermore, we conduct comparisons with standard CNN models, highlighting the improved performance of the BCNN model in identifying complex cases that require further inspections.\n\n\nReference: Mfundo Monchwe, Ibidun C. Obagbuwa, Alfred Mwanza. Coronavirus Lung Image Classification With Uncertainty Estimation Using Bayesian Convolutional Neural Networks In: Hammouch, Z., Lahby, M., Baleanu, D. (eds) Mathematical Modeling and Intelligent Control for Combating Pandemics. Springer Optimization and Its Applications, vol 203. Springer, Cham. https://doi.org/10.1007/978-3-031-33183-1_8"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "RFM analysis is a powerful technique used by companies to better understand customer behaviour and optimize engagement strategies. It revolves around three key dimensions: recency, frequency, and monetary value. These dimensions capture essential aspects of customer transactions, providing valuable information for segmentation and personalized marketing campaigns.\nThe given dataset is provided by an e-commerce platform containing customer transaction data including customer ID, purchase date, transaction amount, product information, ID command and location. The platform aims to leverage RFM (recency, frequency, monetary value) analysis to segment customers and optimize customer engagement strategies.\n\nRFM analysis is a powerful technique used by companies to better understand customer behaviour and optimize engagement strategies. It revolves around three key dimensions: recency, frequency, and monetary value.\nThese dimensions capture essential aspects of customer transactions, providing valuable information for segmentation and personalized marketing campaigns.\nThe given dataset is provided by an e-commerce platform containing customer transaction data including customer ID, purchase date, transaction amount, product information, ID command and location.\nThe platform aims to leverage RFM (recency, frequency, monetary value) analysis to segment customers and optimize customer engagement strategies.\n\n\n\nThe analysis provides insights into customer behavior and identification of high-value customers, at-risk customers, and potential opportunities for personalized marketing campaigns. The following tasks were performed:\n\nRFM analysis was performed on the given dataset to segment customers into different groups based on their RFM scores.\nA detailed analysis of the customer segments was provided, including the distribution of RFM scores, the characteristics of each segment, and actionable insights for the platform to optimize customer engagement strategies.\nThe following table shows the RFM customer segments and their corresponding RFM score ranges:\n\n\n\nRFM Customer Segment\nRFM Score Range\n\n\n\n\nChampions\n9-15\n\n\nPotential\n6-8\n\n\nAt-Risk Customers\n5\n\n\nCan’t Lose Them\n4-5\n\n\nLost Customers\n3\n\n\n\n\n\n\n\nThe RFM analysis provides valuable insights into customer behavior and segmentation, enabling the platform to optimize customer engagement strategies and improve customer satisfaction. The platform can use the insights gained from the analysis to identify high-value customers, at-risk customers, and potential opportunities for personalized marketing campaigns.\n\\[\nargmin_{C_1, \\ldots, C_K} \\sum_{k=1}^{K} \\sum_{x \\in S_k} | x - C_k |^2\n\\]\nIn summary, clustering is a powerful technique for grouping similar data points together, and K-means clustering is a popular algorithm for many applications, including customer segmentation. By using clustering to identify groups of customers with similar behavior, we can develop targeted marketing strategies to improve customer retention and increase sales."
  },
  {
    "objectID": "projects.html#digitizing-mining",
    "href": "projects.html#digitizing-mining",
    "title": "Projects",
    "section": "Digitizing Mining",
    "text": "Digitizing Mining\n\nDesigned and developed analytical web applications that enabled the digitization and analysis of complex mining documents.\nProgrammed functionalities that leveraged advanced techniques in descriptive, diagnostic, and predictive analytics to provide valuable insights to mining stakeholders.\nMining Document Digitizer Application link: Web link\nMining Data Analytics Web Application link: Web link\nSkills: R, Topic Modelling, Text Mining, K-means Clustering, Regression Analysis, OCR, Data Visualization"
  },
  {
    "objectID": "projects.html#bank-customer-churn",
    "href": "projects.html#bank-customer-churn",
    "title": "Projects",
    "section": "Bank Customer Churn",
    "text": "Bank Customer Churn\n\nDeveloped a Bank Customer prediction model using machine learning techniques such as xgboost to accurately identify customers at risk of leaving the bank.\nDeployed the model within a Streamlit application, allowing for user-friendly interaction and real-time predictions based on customer data.\nLeveraged the eli5 library for model interpretability, providing insightful explanations for predictions.\nStreamlit app link: Web link\nSkills: Python, Pandas, Joblib, eli5"
  },
  {
    "objectID": "projects.html#covid-19-classification",
    "href": "projects.html#covid-19-classification",
    "title": "Projects",
    "section": "COVID-19 Classification",
    "text": "COVID-19 Classification\n\nBuilt a Bayesian CNN model in Python to classify patients with COVID-19 using CT scan images with measurements of uncertainty.\nDemonstrated the potential of this approach to improve the accuracy and reliability of COVID-19 diagnosis in a research paper.\nSkills: Python, Deep Learning, TensorFlow, Image Processing, Computer Vision, Bayesian Inference"
  },
  {
    "objectID": "projects.html#mining-process-and-flotation-plant-database",
    "href": "projects.html#mining-process-and-flotation-plant-database",
    "title": "Projects",
    "section": "Mining Process and Flotation Plant Database",
    "text": "Mining Process and Flotation Plant Database\nThe main goal is to use this data to predict how much impurity is in the ore concentrate. As this impurity is measured every hour, if we can predict how much silica (impurity) is in the ore concentrate, we can help the engineers, giving them early information to take actions (empowering)!\nHence, they will be able to take corrective actions in advance (reduce impurity, if it is the case) and also help the environment (reducing the amount of ore that goes to tailings as you reduce silica in the ore concentrate).\n\n\n\n\n\n\nNote\n\n\n\nThe first column shows time and date range (from march of 2017 until september of 2017). Some columns were sampled every 20 second. Others were sampled on a hourly base.\nThe second and third columns are quality measures of the iron ore pulp right before it is fed into the flotation plant. Column 4 until column 8 are the most important variables that impact in the ore quality in the end of the process. From column 9 until column 22, we can see process data level and air flow inside the flotation columns, which also impact in ore quality. The last two columns are the final iron ore pulp quality measurement from the lab.\nTarget is to predict the last column, which is the % of silica in the iron ore concentrate."
  },
  {
    "objectID": "projects.html#weather-forecast",
    "href": "projects.html#weather-forecast",
    "title": "Projects",
    "section": "Weather Forecast",
    "text": "Weather Forecast\n\nDescription:\nWeather forecasting is the task of forecasting weather conditions for a given location and time. With the use of weather data and algorithms, it is possible to predict weather conditions for the next n number of days.\nFor forecasting weather using Python, we need a dataset containing historical weather data based on a particular location.\nTo Download the dataset, click on the link."
  },
  {
    "objectID": "projects.html#api-spotify-requests",
    "href": "projects.html#api-spotify-requests",
    "title": "Projects",
    "section": "API Spotify Requests",
    "text": "API Spotify Requests\n\nThis project is a simple API request to Spotify API. It is a simple project to show how to use API requests in Python.\nThe goal of this project is to get the top 10 songs of an artist and create a playlist with them.\nCreated a scripts that generates music recommmendations based on a seed track using the Spotify API. Which demonstrated how to authenticate with the API using client credentials and how to make request for music recommendations.\nCreated a script that demonstrates how to retrieve information about a track, artist, album and playlist using the Spotify API. Which demonstrated how to authenticate with the API using client credentials and how to make request for artist recommendations.\nCreated a Spotify Playlist Data Collection script, which in return shows an example of how to authenticate the API using client credentials and how to make request for playlist data.\nFor more information on how to collect data from a Spotify playlist using the Spotify API, please refer to the Spotify Web API documentation"
  },
  {
    "objectID": "projects.html#ab-testing-for-website-themes",
    "href": "projects.html#ab-testing-for-website-themes",
    "title": "Projects",
    "section": "A/B Testing for Website Themes",
    "text": "A/B Testing for Website Themes\nThis project analyzes the performance of two different themes for a website using A/B testing. The goal is to determine which theme yields better user engagement, purchases, and conversion rates.\n\nDataset\nThe dataset contains the following metrics for each theme:\n\nClick Through Rate\nConversion Rate\nBounce Rate\n\n\n\nHypothesis Testing\nWe performed a t-test for each metric to compare the means of the two groups (Light Theme and Dark Theme). We calculated the mean, standard deviation, t-statistic, p-value, and effect size for each metric.\nBased on the results of the hypothesis tests, we cannot conclude that one theme yields better user engagement, purchases, and conversion rates than the other. For Click Through Rate and Bounce Rate, the Dark Theme had a higher mean than the Light Theme, but the difference was not statistically significant (p-value &gt; 0.05). For Conversion Rate, there was no statistically significant difference between the two themes (p-value &gt; 0.05).\n\n\nConclusion\nWe cannot make a definitive conclusion about which theme is better based on these results. However, you can use these results to inform your decision about which theme to use for your website."
  },
  {
    "objectID": "projects.html#e-commerce-rfm-analysis",
    "href": "projects.html#e-commerce-rfm-analysis",
    "title": "Projects",
    "section": "",
    "text": "RFM analysis is a powerful technique used by companies to better understand customer behaviour and optimize engagement strategies. It revolves around three key dimensions: recency, frequency, and monetary value. These dimensions capture essential aspects of customer transactions, providing valuable information for segmentation and personalized marketing campaigns.\nThe given dataset is provided by an e-commerce platform containing customer transaction data including customer ID, purchase date, transaction amount, product information, ID command and location. The platform aims to leverage RFM (recency, frequency, monetary value) analysis to segment customers and optimize customer engagement strategies.\n\nRFM analysis is a powerful technique used by companies to better understand customer behaviour and optimize engagement strategies. It revolves around three key dimensions: recency, frequency, and monetary value.\nThese dimensions capture essential aspects of customer transactions, providing valuable information for segmentation and personalized marketing campaigns.\nThe given dataset is provided by an e-commerce platform containing customer transaction data including customer ID, purchase date, transaction amount, product information, ID command and location.\nThe platform aims to leverage RFM (recency, frequency, monetary value) analysis to segment customers and optimize customer engagement strategies.\n\n\n\nThe analysis provides insights into customer behavior and identification of high-value customers, at-risk customers, and potential opportunities for personalized marketing campaigns. The following tasks were performed:\n\nRFM analysis was performed on the given dataset to segment customers into different groups based on their RFM scores.\nA detailed analysis of the customer segments was provided, including the distribution of RFM scores, the characteristics of each segment, and actionable insights for the platform to optimize customer engagement strategies.\nThe following table shows the RFM customer segments and their corresponding RFM score ranges:\n\n\n\nRFM Customer Segment\nRFM Score Range\n\n\n\n\nChampions\n9-15\n\n\nPotential\n6-8\n\n\nAt-Risk Customers\n5\n\n\nCan’t Lose Them\n4-5\n\n\nLost Customers\n3\n\n\n\n\n\n\n\nThe RFM analysis provides valuable insights into customer behavior and segmentation, enabling the platform to optimize customer engagement strategies and improve customer satisfaction. The platform can use the insights gained from the analysis to identify high-value customers, at-risk customers, and potential opportunities for personalized marketing campaigns.\n\\[\nargmin_{C_1, \\ldots, C_K} \\sum_{k=1}^{K} \\sum_{x \\in S_k} | x - C_k |^2\n\\]\nIn summary, clustering is a powerful technique for grouping similar data points together, and K-means clustering is a popular algorithm for many applications, including customer segmentation. By using clustering to identify groups of customers with similar behavior, we can develop targeted marketing strategies to improve customer retention and increase sales."
  }
]